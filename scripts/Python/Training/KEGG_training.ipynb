{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python version 3.11.7\n",
    "import pkg_resources\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from boruta import BorutaPy \n",
    "import optuna \n",
    "import joblib \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "import pickle \n",
    "from statannot import add_stat_annotation \n",
    "import shap\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "#for boruta\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_dir = 'dataset/'\n",
    "KEGG_key = 'KEGG_'\n",
    "all_files = os.listdir(data_dir)\n",
    "KEGG_files = [file for file in all_files if KEGG_key in file and file.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_dfs = {}\n",
    "for file in KEGG_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    df_name = file.replace('.csv', '')  # Remove the file extension from the file name\n",
    "    df_name = df_name.replace('KEGG_', '')\n",
    "    df_name = df_name.replace('_frame', '')\n",
    "    raw_dfs[df_name] = pd.read_csv(file_path, index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in raw_dfs.items():\n",
    "    print(f'Raw Dim of {df_name} ::: {df.shape}')\n",
    "    df = df[df.columns.difference(['Unnamed: 0'])]\n",
    "    df = df.dropna(how = 'any')\n",
    "    print(f'After processing {df_name} ::: {df.shape}')\n",
    "    print('\\n')\n",
    "    raw_dfs[df_name] = df\n",
    "dfs = raw_dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost Regressor\n",
    "def XGBRegressor_objective(trial):\n",
    "    params = {\n",
    "        'eval_metric' : 'rmse',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        \"eta\": trial.suggest_float(\"eta\",1e-2,0.1,log = True),\n",
    "        # L2 regularization weight.\n",
    "        \"reg_lambda\": trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
    "        # L1 regularization weight.\n",
    "        \"reg_alpha\": trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6,1,step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 0.9, step=0.1),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.2, 0.9, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 9),\n",
    "        'min_child_weight' :  trial.suggest_int(\"min_child_weight\", 2, 10),\n",
    "        'n_jobs' : -1,\n",
    "    }\n",
    "    model = XGBRegressor(**params)\n",
    "    xg_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(xg_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dfs.items():\n",
    "    X = df.drop('ARID1A', axis=1)\n",
    "    y = df['ARID1A']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(XGBRegressor_objective, n_trials = 500)\n",
    "    best_params = study.best_params\n",
    "    cur_model = XGBRegressor(**best_params)\n",
    "    cur_model.fit(X_train, y_train)\n",
    "    joblib.dump(cur_model,f'Models/KEGG_Model/{df_name}_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
