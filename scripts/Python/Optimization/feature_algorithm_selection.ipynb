{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python version 3.11.7\n",
    "import pkg_resources\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from boruta import BorutaPy \n",
    "import optuna \n",
    "import joblib \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "import pickle \n",
    "from statannot import add_stat_annotation \n",
    "import shap\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "#for boruta\n",
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UCEC_full = pd.read_csv(\"dataset/TCGA_UCEC_scaled.csv\",sep=',', index_col=0)\n",
    "UCEC_full = UCEC_full[UCEC_full.columns.difference(['RNA_count'])]\n",
    "UCEC_full = UCEC_full.dropna(how = 'any')\n",
    "UCEC_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column where each feature is located may vary, so you'll need to manually adjust it\n",
    "\n",
    "# UCEC_ARID1A: TCPA protein expression column\n",
    "UCEC_ARID1A = UCEC_full.iloc[:,0]\n",
    "UCEC_RNA = UCEC_full.iloc[:,68]\n",
    "UCEC_Mut = UCEC_full.iloc[:,[2,3,4,6]]\n",
    "UCEC_CNV = UCEC_full.iloc[:,1]\n",
    "UCEC_Met = UCEC_full.iloc[:,7:35]\n",
    "UCEC_miRNA = UCEC_full.iloc[:,35:68]\n",
    "UCEC_Biogrid = pd.read_csv(\"/dataset/Biogrid_feature.csv\",sep=',', index_col=0)\n",
    "UCEC_Biogrid = UCEC_Biogrid.loc[UCEC_full.index,:]\n",
    "UCEC_KEGG = pd.read_csv(\"/dataset/KEGG_feature.csv\",sep=',', index_col=0)\n",
    "UCEC_KEGG = UCEC_KEGG.loc[UCEC_full.index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result_matrix = pd.DataFrame(columns=['train_RMSE','train_R2','train_R','test_RMSE','test_R2','test_R'])\n",
    "#Make result matrix for each random seed \n",
    "UCEC_data_list = ['RNA','CNV','miRNA','Met','Mut','KEGG','Biogrid'] #7\n",
    "Models = ['LinearRegression','Ridge','SVR','ElasticNet','RandomForestRegressor','XGBRegressor','LGBMRegressor'] #7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Linear Regression\n",
    "linear = LinearRegression(n_jobs= -1)\n",
    "\n",
    "# Define SVM Regressor\n",
    "def SVR_objective(trial):\n",
    "    params = { \n",
    "        #kernel funciton\n",
    "        'kernel' : trial.suggest_categorical('kernel',['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        # how far influences the calculation of plausible line of separation\n",
    "        'gamma': trial.suggest_float('gamma', 1e-5, 1, log=True),\n",
    "        # C : regularisation, how much error is bearable, higher = overfitting \n",
    "        'C': trial.suggest_float('C', 1e-5, 1, log=True)\n",
    "    }\n",
    "    \n",
    "    model = SVR(**params)\n",
    "    svr_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(svr_cv)\n",
    "\n",
    "# Define Ridge Regressor\n",
    "def Ridge_objective(trial):\n",
    "    params = { \n",
    "        # alpha = regularization strength\n",
    "        'alpha' : trial.suggest_float('alpha', 0.1, 100, log=True),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "    }\n",
    "    model = Ridge(**params)\n",
    "    ridge_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(ridge_cv)\n",
    "\n",
    "# Define ElasticNet Regressor\n",
    "def ElasticNet_objective(trial):\n",
    "    params = { \n",
    "        # alpha = regularization strength\n",
    "        'alpha' : trial.suggest_float('alpha', 0.1, 100, log=True),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'l1_ratio' : trial.suggest_float('l1_ratio', 0.01, 1.0, log=True),\n",
    "    }\n",
    "    model = ElasticNet(**params)\n",
    "    elastic_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(elastic_cv)\n",
    "\n",
    "# Define Randomforest Regressor\n",
    "def RandomForestRegressor_objective(trial):\n",
    "    params = { \n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap',[True, False]),\n",
    "        'n_jobs' : -1,\n",
    "    }\n",
    "    model = RandomForestRegressor(**params)\n",
    "    rf_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(rf_cv)\n",
    "\n",
    "# Define XGBoost Regressor\n",
    "def XGBRegressor_objective(trial):\n",
    "    params = {\n",
    "        'eval_metric' : 'rmse',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        \"eta\": trial.suggest_float(\"eta\",1e-2,0.1,log = True),\n",
    "        # L2 regularization weight.\n",
    "        \"reg_lambda\": trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
    "        # L1 regularization weight.\n",
    "        \"reg_alpha\": trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6,1,step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 0.9, step=0.1),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.2, 0.9, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 9),\n",
    "        'min_child_weight' :  trial.suggest_int(\"min_child_weight\", 2, 10),\n",
    "        'n_jobs' : -1,\n",
    "    }\n",
    "    model = XGBRegressor(**params)\n",
    "    xg_cv = -1 * cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs= -1)\n",
    "    return np.mean(xg_cv)\n",
    "\n",
    "# Define LGBM Regressor \n",
    "def LGBMRegressor_objective(trial):\n",
    "    params = {\n",
    "        'metric': 'rmse',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log = True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6,1,step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1, step=0.1),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 9),\n",
    "        'min_child_weight' :  trial.suggest_int(\"min_child_weight\", 2, 10),\n",
    "        'early_stopping_round': 100,\n",
    "        'n_jobs' : -1,\n",
    "        'verbose' : -100\n",
    "    }\n",
    "    X_cv, X_eval, y_cv, y_eval = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    fit_params = {\n",
    "    'eval_set': [(X_eval, y_eval)]\n",
    "    }\n",
    "    model = LGBMRegressor(**params)\n",
    "    lgb_cv = -1 * cross_val_score(model, X_cv, y_cv, cv=5, scoring='neg_mean_squared_error', n_jobs= -1,\n",
    "                                  fit_params=fit_params, verbose = 0)\n",
    "    return np.mean(lgb_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop for 10 different random seed\n",
    "for i in range(10):\n",
    "    globals()['Result_matrix_'+ str(i)] = pd.DataFrame(columns=['train_RMSE','train_R2','train_R','test_RMSE','test_R2','test_R'])\n",
    "    np.random.seed(i)\n",
    "    for level in UCEC_data_list:\n",
    "        X = globals()['UCEC_' + level]\n",
    "        y = UCEC_ARID1A\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        if (level in ['KO','RNA','CNV','Biogrid']):\n",
    "            X_train = np.array(X_train).reshape(-1, 1)\n",
    "            X_test = np.array(X_test).reshape(-1, 1)\n",
    "        for model in Models:\n",
    "            if model == 'LinearRegression':\n",
    "                cur_model = LinearRegression(n_jobs= -1)\n",
    "            else:\n",
    "                study = optuna.create_study(direction='minimize')\n",
    "                study.optimize(globals()[model+'_objective'], n_trials=100) #10 : test trial \n",
    "                best_params = study.best_params\n",
    "                cur_model = globals()[model](**best_params)\n",
    "            cur_model.fit(X_train, y_train)\n",
    "            train_y_pred = cur_model.predict(X_train)\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, train_y_pred))\n",
    "            train_r2 = r2_score(y_train, train_y_pred)\n",
    "            train_corr = np.corrcoef(y_train, train_y_pred)[0,1]\n",
    "            test_y_pred = cur_model.predict(X_test)\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, test_y_pred))\n",
    "            test_r2 = r2_score(y_test, test_y_pred)\n",
    "            test_corr = np.corrcoef(y_test, test_y_pred)[0,1]\n",
    "            globals()['Result_matrix_'+ str(i)].loc[level+'_'+model] = [train_rmse,train_r2,train_corr,test_rmse,test_r2,test_corr]\n",
    "    globals()['Result_matrix_'+ str(i)].to_csv(\"Result_matrix/Result_matrix_\"+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULT Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_matrix_0 = pd.read_csv(\"Result_matrix/Result_matrix_0.csv\", index_col=0)\n",
    "Result_matrix_1 = pd.read_csv(\"Result_matrix/Result_matrix_1.csv\", index_col=0)\n",
    "Result_matrix_2 = pd.read_csv(\"Result_matrix/Result_matrix_2.csv\", index_col=0)\n",
    "Result_matrix_3 = pd.read_csv(\"Result_matrix/Result_matrix_3.csv\", index_col=0)\n",
    "Result_matrix_4 = pd.read_csv(\"Result_matrix/Result_matrix_4.csv\", index_col=0)\n",
    "Result_matrix_5 = pd.read_csv(\"Result_matrix/Result_matrix_5.csv\", index_col=0)\n",
    "Result_matrix_6 = pd.read_csv(\"Result_matrix/Result_matrix_6.csv\", index_col=0)\n",
    "Result_matrix_7 = pd.read_csv(\"Result_matrix/Result_matrix_7.csv\", index_col=0)\n",
    "Result_matrix_8 = pd.read_csv(\"Result_matrix/Result_matrix_8.csv\", index_col=0)\n",
    "Result_matrix_9 = pd.read_csv(\"Result_matrix/Result_matrix_9.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list([Result_matrix_0,Result_matrix_1,Result_matrix_2,Result_matrix_3,Result_matrix_4,\n",
    "           Result_matrix_5,Result_matrix_6,Result_matrix_7,Result_matrix_8,Result_matrix_9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_Result_matrix = pd.concat(dfs, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = concatenated_Result_matrix.rank(axis=0, ascending= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rank of test_R2\n",
    "rank_df['test_R2'].mean(axis =1 ).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rank of test_R2\n",
    "rank_df['test_RMSE'].mean(axis =1 ).sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rank of test_R2\n",
    "rank_df['test_R'].mean(axis =1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ranking grouped by Omics level \n",
    "\n",
    "omics_Result_matrix = pd.DataFrame(concatenated_Result_matrix)\n",
    "omics_Result_matrix.index = concatenated_Result_matrix.index.str.split('_').str[0]\n",
    "omics_Result_matrix = omics_Result_matrix.groupby(level = 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_omics_Result_matrix = pd.DataFrame(index=UCEC_data_list)\n",
    "avg_omics_Result_matrix['train_RMSE'] = omics_Result_matrix['train_RMSE'].mean(axis = 1)\n",
    "avg_omics_Result_matrix['train_R2'] = omics_Result_matrix['train_R2'].mean(axis = 1)\n",
    "avg_omics_Result_matrix['train_R'] = omics_Result_matrix['train_R'].mean(axis = 1)\n",
    "avg_omics_Result_matrix['test_RMSE'] = omics_Result_matrix['test_RMSE'].mean(axis = 1)\n",
    "avg_omics_Result_matrix['test_R2'] = omics_Result_matrix['test_R2'].mean(axis = 1)\n",
    "avg_omics_Result_matrix['test_R'] = omics_Result_matrix['test_R'].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ranking grouped by Algorithm \n",
    "algorithm_Result_matrix = pd.DataFrame(concatenated_Result_matrix)\n",
    "algorithm_Result_matrix.index = concatenated_Result_matrix.index.str.split('_').str[1]\n",
    "algorithm_Result_matrix = algorithm_Result_matrix.groupby(level = 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_algorithm_Result_matrix = pd.DataFrame(index=Models)\n",
    "avg_algorithm_Result_matrix['train_RMSE'] = algorithm_Result_matrix['train_RMSE'].mean(axis = 1)\n",
    "avg_algorithm_Result_matrix['train_R2'] = algorithm_Result_matrix['train_R2'].mean(axis = 1)\n",
    "avg_algorithm_Result_matrix['train_R'] = algorithm_Result_matrix['train_R'].mean(axis = 1)\n",
    "avg_algorithm_Result_matrix['test_RMSE'] = algorithm_Result_matrix['test_RMSE'].mean(axis = 1)\n",
    "avg_algorithm_Result_matrix['test_R2'] = algorithm_Result_matrix['test_R2'].mean(axis = 1)\n",
    "avg_algorithm_Result_matrix['test_R'] = algorithm_Result_matrix['test_R'].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_algorithm_Result_matrix, x = avg_algorithm_Result_matrix.index, y = \"test_R2\",\n",
    "            order = avg_algorithm_Result_matrix.sort_values('test_R2').index)\n",
    "plt.xticks(rotation = 45,ha = 'right')\n",
    "plt.title(\"R-Squared\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_algorithm_Result_matrix, x = avg_algorithm_Result_matrix.index, y = \"test_R\",\n",
    "            order = avg_algorithm_Result_matrix.sort_values('test_R').index)\n",
    "plt.xticks(rotation = 45,ha = 'right')\n",
    "plt.title(\"R\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_algorithm_Result_matrix, x = avg_algorithm_Result_matrix.index, y = \"test_RMSE\",\n",
    "            order = avg_algorithm_Result_matrix.sort_values('test_RMSE').index)\n",
    "plt.xticks(rotation = 45,ha = 'right')\n",
    "plt.title(\"RMSE\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_omics_Result_matrix, x = avg_omics_Result_matrix.index, y = \"test_RMSE\",\n",
    "            order = avg_omics_Result_matrix.sort_values('test_RMSE').index)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Omics level : test_RMSE\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_omics_Result_matrix, x = avg_omics_Result_matrix.index, y = \"test_R2\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Omics level : test_R2\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(avg_omics_Result_matrix, x = avg_omics_Result_matrix.index, y = \"test_R\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title(\"Omics level : test_R\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCEC_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
